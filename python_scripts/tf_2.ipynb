{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>useful</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'2013-05-07 04:34:36'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'ujmEBvifdJM6h6RLv4wQIg'</td>\n",
       "      <td>total bill for this horrible service over $8gs...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'hG7b0MtEbXx5QzbzE6C_VA'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Q1sbwvVQXV2734tPgoKj4Q'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'2017-01-14 21:30:33'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'NZnhc2sEQy3RmzKTZnqtwQ'</td>\n",
       "      <td>i adore travis at the hard rocks new kelly car...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yXQM5uF2jS6es16SJzNHfg'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'GJXCdrto3ASJOqKeVWPi6Q'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'2016-11-09 20:09:03'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'WTqjgwHlXbSFevF32_DJVw'</td>\n",
       "      <td>i have to say that this office really has it t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'n6-Gk65cPZL6Uz8qRm3NYw'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2TzJjDVDEuAW6MR5Vuc1ug'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'2018-01-09 20:56:38'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ikCg8xy5JIg_NGPx-MSIDA'</td>\n",
       "      <td>went in for a lunch steak sandwich was delicio...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'dacAIZ6fTM6mqwW5uxkskg'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yi0R0Ugj_xUx_Nek0-_Qig'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'2018-01-30 23:07:38'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>b'b1b1eb3uo-w561D0ZfCEiQ'</td>\n",
       "      <td>today was my second out of three sessions i ha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ssoyf2_x0EQMed6fgHeMyQ'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'11a8sVPMUFtaC7_ABRkmtw'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  useful                business_id  \\\n",
       "0  b'2013-05-07 04:34:36'     6.0  b'ujmEBvifdJM6h6RLv4wQIg'   \n",
       "1  b'2017-01-14 21:30:33'     0.0  b'NZnhc2sEQy3RmzKTZnqtwQ'   \n",
       "2  b'2016-11-09 20:09:03'     3.0  b'WTqjgwHlXbSFevF32_DJVw'   \n",
       "3  b'2018-01-09 20:56:38'     0.0  b'ikCg8xy5JIg_NGPx-MSIDA'   \n",
       "4  b'2018-01-30 23:07:38'     7.0  b'b1b1eb3uo-w561D0ZfCEiQ'   \n",
       "\n",
       "                                                text  funny  \\\n",
       "0  total bill for this horrible service over $8gs...    1.0   \n",
       "1  i adore travis at the hard rocks new kelly car...    0.0   \n",
       "2  i have to say that this office really has it t...    0.0   \n",
       "3  went in for a lunch steak sandwich was delicio...    0.0   \n",
       "4  today was my second out of three sessions i ha...    0.0   \n",
       "\n",
       "                     user_id  stars  cool                  review_id  \n",
       "0  b'hG7b0MtEbXx5QzbzE6C_VA'    1.0   0.0  b'Q1sbwvVQXV2734tPgoKj4Q'  \n",
       "1  b'yXQM5uF2jS6es16SJzNHfg'    5.0   0.0  b'GJXCdrto3ASJOqKeVWPi6Q'  \n",
       "2  b'n6-Gk65cPZL6Uz8qRm3NYw'    5.0   0.0  b'2TzJjDVDEuAW6MR5Vuc1ug'  \n",
       "3  b'dacAIZ6fTM6mqwW5uxkskg'    5.0   0.0  b'yi0R0Ugj_xUx_Nek0-_Qig'  \n",
       "4  b'ssoyf2_x0EQMed6fgHeMyQ'    1.0   0.0  b'11a8sVPMUFtaC7_ABRkmtw'  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('review_test_clean.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['text'] = reviews['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = reviews[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>useful</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'2013-05-07 04:34:36'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'ujmEBvifdJM6h6RLv4wQIg'</td>\n",
       "      <td>total bill for this horrible service over $8gs...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'hG7b0MtEbXx5QzbzE6C_VA'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Q1sbwvVQXV2734tPgoKj4Q'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'2017-01-14 21:30:33'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'NZnhc2sEQy3RmzKTZnqtwQ'</td>\n",
       "      <td>i adore travis at the hard rocks new kelly car...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yXQM5uF2jS6es16SJzNHfg'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'GJXCdrto3ASJOqKeVWPi6Q'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'2016-11-09 20:09:03'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'WTqjgwHlXbSFevF32_DJVw'</td>\n",
       "      <td>i have to say that this office really has it t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'n6-Gk65cPZL6Uz8qRm3NYw'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2TzJjDVDEuAW6MR5Vuc1ug'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'2018-01-09 20:56:38'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ikCg8xy5JIg_NGPx-MSIDA'</td>\n",
       "      <td>went in for a lunch steak sandwich was delicio...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'dacAIZ6fTM6mqwW5uxkskg'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yi0R0Ugj_xUx_Nek0-_Qig'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'2018-01-30 23:07:38'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>b'b1b1eb3uo-w561D0ZfCEiQ'</td>\n",
       "      <td>today was my second out of three sessions i ha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ssoyf2_x0EQMed6fgHeMyQ'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'11a8sVPMUFtaC7_ABRkmtw'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  useful                business_id  \\\n",
       "0  b'2013-05-07 04:34:36'     6.0  b'ujmEBvifdJM6h6RLv4wQIg'   \n",
       "1  b'2017-01-14 21:30:33'     0.0  b'NZnhc2sEQy3RmzKTZnqtwQ'   \n",
       "2  b'2016-11-09 20:09:03'     3.0  b'WTqjgwHlXbSFevF32_DJVw'   \n",
       "3  b'2018-01-09 20:56:38'     0.0  b'ikCg8xy5JIg_NGPx-MSIDA'   \n",
       "4  b'2018-01-30 23:07:38'     7.0  b'b1b1eb3uo-w561D0ZfCEiQ'   \n",
       "\n",
       "                                                text  funny  \\\n",
       "0  total bill for this horrible service over $8gs...    1.0   \n",
       "1  i adore travis at the hard rocks new kelly car...    0.0   \n",
       "2  i have to say that this office really has it t...    0.0   \n",
       "3  went in for a lunch steak sandwich was delicio...    0.0   \n",
       "4  today was my second out of three sessions i ha...    0.0   \n",
       "\n",
       "                     user_id  stars  cool                  review_id  \n",
       "0  b'hG7b0MtEbXx5QzbzE6C_VA'    1.0   0.0  b'Q1sbwvVQXV2734tPgoKj4Q'  \n",
       "1  b'yXQM5uF2jS6es16SJzNHfg'    5.0   0.0  b'GJXCdrto3ASJOqKeVWPi6Q'  \n",
       "2  b'n6-Gk65cPZL6Uz8qRm3NYw'    5.0   0.0  b'2TzJjDVDEuAW6MR5Vuc1ug'  \n",
       "3  b'dacAIZ6fTM6mqwW5uxkskg'    5.0   0.0  b'yi0R0Ugj_xUx_Nek0-_Qig'  \n",
       "4  b'ssoyf2_x0EQMed6fgHeMyQ'    1.0   0.0  b'11a8sVPMUFtaC7_ABRkmtw'  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>useful</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>review_id</th>\n",
       "      <th>lemmatized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'2013-05-07 04:34:36'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'ujmEBvifdJM6h6RLv4wQIg'</td>\n",
       "      <td>total bill for this horrible service over $8gs...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'hG7b0MtEbXx5QzbzE6C_VA'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Q1sbwvVQXV2734tPgoKj4Q'</td>\n",
       "      <td>total bill for this horrible service over $8gs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'2017-01-14 21:30:33'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'NZnhc2sEQy3RmzKTZnqtwQ'</td>\n",
       "      <td>i adore travis at the hard rocks new kelly car...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yXQM5uF2jS6es16SJzNHfg'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'GJXCdrto3ASJOqKeVWPi6Q'</td>\n",
       "      <td>i adore travis at the hard rock new kelly card...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'2016-11-09 20:09:03'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'WTqjgwHlXbSFevF32_DJVw'</td>\n",
       "      <td>i have to say that this office really has it t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'n6-Gk65cPZL6Uz8qRm3NYw'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2TzJjDVDEuAW6MR5Vuc1ug'</td>\n",
       "      <td>i have to say that this office really ha it to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'2018-01-09 20:56:38'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ikCg8xy5JIg_NGPx-MSIDA'</td>\n",
       "      <td>went in for a lunch steak sandwich was delicio...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'dacAIZ6fTM6mqwW5uxkskg'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yi0R0Ugj_xUx_Nek0-_Qig'</td>\n",
       "      <td>went in for a lunch steak sandwich wa deliciou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'2018-01-30 23:07:38'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>b'b1b1eb3uo-w561D0ZfCEiQ'</td>\n",
       "      <td>today was my second out of three sessions i ha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ssoyf2_x0EQMed6fgHeMyQ'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'11a8sVPMUFtaC7_ABRkmtw'</td>\n",
       "      <td>today wa my second out of three session i had ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  useful                business_id  \\\n",
       "0  b'2013-05-07 04:34:36'     6.0  b'ujmEBvifdJM6h6RLv4wQIg'   \n",
       "1  b'2017-01-14 21:30:33'     0.0  b'NZnhc2sEQy3RmzKTZnqtwQ'   \n",
       "2  b'2016-11-09 20:09:03'     3.0  b'WTqjgwHlXbSFevF32_DJVw'   \n",
       "3  b'2018-01-09 20:56:38'     0.0  b'ikCg8xy5JIg_NGPx-MSIDA'   \n",
       "4  b'2018-01-30 23:07:38'     7.0  b'b1b1eb3uo-w561D0ZfCEiQ'   \n",
       "\n",
       "                                                text  funny  \\\n",
       "0  total bill for this horrible service over $8gs...    1.0   \n",
       "1  i adore travis at the hard rocks new kelly car...    0.0   \n",
       "2  i have to say that this office really has it t...    0.0   \n",
       "3  went in for a lunch steak sandwich was delicio...    0.0   \n",
       "4  today was my second out of three sessions i ha...    0.0   \n",
       "\n",
       "                     user_id  stars  cool                  review_id  \\\n",
       "0  b'hG7b0MtEbXx5QzbzE6C_VA'    1.0   0.0  b'Q1sbwvVQXV2734tPgoKj4Q'   \n",
       "1  b'yXQM5uF2jS6es16SJzNHfg'    5.0   0.0  b'GJXCdrto3ASJOqKeVWPi6Q'   \n",
       "2  b'n6-Gk65cPZL6Uz8qRm3NYw'    5.0   0.0  b'2TzJjDVDEuAW6MR5Vuc1ug'   \n",
       "3  b'dacAIZ6fTM6mqwW5uxkskg'    5.0   0.0  b'yi0R0Ugj_xUx_Nek0-_Qig'   \n",
       "4  b'ssoyf2_x0EQMed6fgHeMyQ'    1.0   0.0  b'11a8sVPMUFtaC7_ABRkmtw'   \n",
       "\n",
       "                                  lemmatized_reviews  \n",
       "0  total bill for this horrible service over $8gs...  \n",
       "1  i adore travis at the hard rock new kelly card...  \n",
       "2  i have to say that this office really ha it to...  \n",
       "3  went in for a lunch steak sandwich wa deliciou...  \n",
       "4  today wa my second out of three session i had ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalized using lemmatization\n",
    "def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "reviews_train['lemmatized_reviews'] = get_lemmatized_text(reviews_train['text'])\n",
    "reviews_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>useful</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>review_id</th>\n",
       "      <th>lemmatized_reviews</th>\n",
       "      <th>no_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'2013-05-07 04:34:36'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'ujmEBvifdJM6h6RLv4wQIg'</td>\n",
       "      <td>total bill for this horrible service over $8gs...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'hG7b0MtEbXx5QzbzE6C_VA'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Q1sbwvVQXV2734tPgoKj4Q'</td>\n",
       "      <td>total bill for this horrible service over $8gs...</td>\n",
       "      <td>total bill horrible service $8gs crook actuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'2017-01-14 21:30:33'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'NZnhc2sEQy3RmzKTZnqtwQ'</td>\n",
       "      <td>i adore travis at the hard rocks new kelly car...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yXQM5uF2jS6es16SJzNHfg'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'GJXCdrto3ASJOqKeVWPi6Q'</td>\n",
       "      <td>i adore travis at the hard rock new kelly card...</td>\n",
       "      <td>adore travis hard rock new kelly cardenas salo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'2016-11-09 20:09:03'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'WTqjgwHlXbSFevF32_DJVw'</td>\n",
       "      <td>i have to say that this office really has it t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'n6-Gk65cPZL6Uz8qRm3NYw'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'2TzJjDVDEuAW6MR5Vuc1ug'</td>\n",
       "      <td>i have to say that this office really ha it to...</td>\n",
       "      <td>say office really ha together organized friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'2018-01-09 20:56:38'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ikCg8xy5JIg_NGPx-MSIDA'</td>\n",
       "      <td>went in for a lunch steak sandwich was delicio...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'dacAIZ6fTM6mqwW5uxkskg'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'yi0R0Ugj_xUx_Nek0-_Qig'</td>\n",
       "      <td>went in for a lunch steak sandwich wa deliciou...</td>\n",
       "      <td>went lunch steak sandwich wa delicious caesar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'2018-01-30 23:07:38'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>b'b1b1eb3uo-w561D0ZfCEiQ'</td>\n",
       "      <td>today was my second out of three sessions i ha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'ssoyf2_x0EQMed6fgHeMyQ'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'11a8sVPMUFtaC7_ABRkmtw'</td>\n",
       "      <td>today wa my second out of three session i had ...</td>\n",
       "      <td>today wa second three session paid although fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  useful                business_id  \\\n",
       "0  b'2013-05-07 04:34:36'     6.0  b'ujmEBvifdJM6h6RLv4wQIg'   \n",
       "1  b'2017-01-14 21:30:33'     0.0  b'NZnhc2sEQy3RmzKTZnqtwQ'   \n",
       "2  b'2016-11-09 20:09:03'     3.0  b'WTqjgwHlXbSFevF32_DJVw'   \n",
       "3  b'2018-01-09 20:56:38'     0.0  b'ikCg8xy5JIg_NGPx-MSIDA'   \n",
       "4  b'2018-01-30 23:07:38'     7.0  b'b1b1eb3uo-w561D0ZfCEiQ'   \n",
       "\n",
       "                                                text  funny  \\\n",
       "0  total bill for this horrible service over $8gs...    1.0   \n",
       "1  i adore travis at the hard rocks new kelly car...    0.0   \n",
       "2  i have to say that this office really has it t...    0.0   \n",
       "3  went in for a lunch steak sandwich was delicio...    0.0   \n",
       "4  today was my second out of three sessions i ha...    0.0   \n",
       "\n",
       "                     user_id  stars  cool                  review_id  \\\n",
       "0  b'hG7b0MtEbXx5QzbzE6C_VA'    1.0   0.0  b'Q1sbwvVQXV2734tPgoKj4Q'   \n",
       "1  b'yXQM5uF2jS6es16SJzNHfg'    5.0   0.0  b'GJXCdrto3ASJOqKeVWPi6Q'   \n",
       "2  b'n6-Gk65cPZL6Uz8qRm3NYw'    5.0   0.0  b'2TzJjDVDEuAW6MR5Vuc1ug'   \n",
       "3  b'dacAIZ6fTM6mqwW5uxkskg'    5.0   0.0  b'yi0R0Ugj_xUx_Nek0-_Qig'   \n",
       "4  b'ssoyf2_x0EQMed6fgHeMyQ'    1.0   0.0  b'11a8sVPMUFtaC7_ABRkmtw'   \n",
       "\n",
       "                                  lemmatized_reviews  \\\n",
       "0  total bill for this horrible service over $8gs...   \n",
       "1  i adore travis at the hard rock new kelly card...   \n",
       "2  i have to say that this office really ha it to...   \n",
       "3  went in for a lunch steak sandwich wa deliciou...   \n",
       "4  today wa my second out of three session i had ...   \n",
       "\n",
       "                                       no_stop_words  \n",
       "0  total bill horrible service $8gs crook actuall...  \n",
       "1  adore travis hard rock new kelly cardenas salo...  \n",
       "2  say office really ha together organized friend...  \n",
       "3  went lunch steak sandwich wa delicious caesar ...  \n",
       "4  today wa second three session paid although fi...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "reviews_train['no_stop_words'] = remove_stop_words(reviews_train['lemmatized_reviews'])\n",
    "reviews_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Word Counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wc_vectorizer = CountVectorizer(binary=False)\n",
    "wc_vectorizer.fit(reviews_train['no_stop_words'])\n",
    "X = wc_vectorizer.transform(reviews_train['no_stop_words'])\n",
    "target = reviews_train['stars']\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.46153846153846156\n",
      "Accuracy for C=0.05: 0.6153846153846154\n",
      "Accuracy for C=0.25: 0.6153846153846154\n",
      "Accuracy for C=0.5: 0.6153846153846154\n",
      "Accuracy for C=1: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "final_wc = LogisticRegression(C=0.05)\n",
    "final_wc.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_val, final_wc.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 5., 5., 5., 1., 4., 3., 1., 2., 5., 4., 1., 4., 4., 1., 5., 4.,\n",
       "       3., 5., 3., 5., 5., 4., 5., 5., 5., 1., 5., 1., 1., 5., 1., 1., 5.,\n",
       "       1., 2., 5., 4., 1., 1., 4., 3., 5., 5., 1., 5., 5., 4., 4., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_wc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(reviews_train['no_stop_words'])\n",
    "X = tfidf_vectorizer.transform(reviews_train['no_stop_words'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.3076923076923077\n",
      "Accuracy for C=0.05: 0.3076923076923077\n",
      "Accuracy for C=0.25: 0.3076923076923077\n",
      "Accuracy for C=0.5: 0.3076923076923077\n",
      "Accuracy for C=1: 0.38461538461538464\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tire', 0.39327490981155194)\n",
      "('walked', 0.3511932877223176)\n",
      "('body', 0.3041437673613223)\n",
      "('hot', 0.2967684737663867)\n",
      "('pot', 0.27618539531686914)\n",
      "('great', -0.3013770845568173)\n",
      "('chicken', -0.26946053497935685)\n",
      "('also', -0.2221686598445839)\n",
      "('amazing', -0.21471638526613623)\n",
      "('friendly', -0.1912565461325712)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        tfidf_vectorizer.get_feature_names(), lr.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "\n",
    "    \n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
